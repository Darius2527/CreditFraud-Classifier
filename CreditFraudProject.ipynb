{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN7q6jAaQlx5lOo5mBaSa4s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Darius2527/CreditFraud-Classifier/blob/main/CreditFraudProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=None\n",
        "#this code is written to make sure that all rows in the dataset are read. Sometimes google colab may be unable to read all the rown when the number of rows is too large\n",
        "chunk_size = 10000\n",
        "df_list = []  # Initialize an empty list to store chunk DataFrames\n",
        "\n",
        "for chunk in pd.read_csv(\"CreditFraud.csv\", chunksize=chunk_size, on_bad_lines='skip'):\n",
        "    df_list.append(chunk)  # Append each chunk DataFrame to the list\n",
        "\n",
        "# Concatenate all chunk DataFrames into a single DataFrame\n",
        "df = pd.concat(df_list, axis=0, ignore_index=True)\n",
        "\n",
        "print(df.shape)  # Check the dimensions of the final DataFrame"
      ],
      "metadata": {
        "id": "bfghDisa_pWi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79cefb36-51bc-44db-ca2b-8541730e2471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(284807, 31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "mJMluQot_6EZ",
        "outputId": "cfffc40a-a07c-446b-afd4-0183cae3a205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "\n",
              "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
              "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
              "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
              "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
              "\n",
              "        V26       V27       V28  Amount  Class  \n",
              "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "1  0.125895 -0.008983  0.014724    2.69      0  \n",
              "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              "3 -0.221929  0.062723  0.061458  123.50      0  \n",
              "4  0.502292  0.219422  0.215153   69.99      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-657991d1-895f-4db1-bad1-f27efec490b3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-657991d1-895f-4db1-bad1-f27efec490b3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-657991d1-895f-4db1-bad1-f27efec490b3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-657991d1-895f-4db1-bad1-f27efec490b3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-580d3763-3281-4703-b482-bfe4d681cb0e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-580d3763-3281-4703-b482-bfe4d681cb0e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-580d3763-3281-4703-b482-bfe4d681cb0e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()\n",
        "#no null values present"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QX8DYz9AUBc",
        "outputId": "07843337-462c-4e51-fc33-b5b69de54027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time      0\n",
              "V1        0\n",
              "V2        0\n",
              "V3        0\n",
              "V4        0\n",
              "V5        0\n",
              "V6        0\n",
              "V7        0\n",
              "V8        0\n",
              "V9        0\n",
              "V10       0\n",
              "V11       0\n",
              "V12       0\n",
              "V13       0\n",
              "V14       0\n",
              "V15       0\n",
              "V16       0\n",
              "V17       0\n",
              "V18       0\n",
              "V19       0\n",
              "V20       0\n",
              "V21       0\n",
              "V22       0\n",
              "V23       0\n",
              "V24       0\n",
              "V25       0\n",
              "V26       0\n",
              "V27       0\n",
              "V28       0\n",
              "Amount    0\n",
              "Class     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#drop unnecessary 'time' column\n",
        "df.drop('Time', axis=1, inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "RjAbPZwFBYUZ",
        "outputId": "c1f144f0-c734-44c1-8668-c9a01a6b5720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "\n",
              "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
              "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
              "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
              "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
              "3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
              "4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n",
              "\n",
              "        V25       V26       V27       V28  Amount  Class  \n",
              "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
              "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
              "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28975b17-e2c1-42a0-bd87-9e43b3faba88\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28975b17-e2c1-42a0-bd87-9e43b3faba88')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-28975b17-e2c1-42a0-bd87-9e43b3faba88 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-28975b17-e2c1-42a0-bd87-9e43b3faba88');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2b093078-4e3d-4954-80d6-b5329824a852\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2b093078-4e3d-4954-80d6-b5329824a852')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2b093078-4e3d-4954-80d6-b5329824a852 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#let us check value count of target variable\n",
        "df['Class'].value_counts()\n",
        "#as we can see it is a highly inbalanced dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qCl6L2wBjNF",
        "outputId": "ad8985d6-cf77-4804-c54b-046dfae4d473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Class\n",
              "0    284315\n",
              "1       492\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.heatmap(df.corr())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "w1sgtdwlB59O",
        "outputId": "75ed75ad-b4b8-4ea9-8eef-69b1a48aa444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#seperating the features and the target\n",
        "X = df.drop('Class', axis=1)\n",
        "Y = df['Class']"
      ],
      "metadata": {
        "id": "LorHOet2CVAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dazSgEIGDYbi",
        "outputId": "1dbbbda1-2563-48cd-d0ca-af24973a3d82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(284807, 29)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJW6OsSTFYE-",
        "outputId": "4438326f-9fbb-48d5-acf1-aa13df60c537"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hd1YtvxqDZZB",
        "outputId": "e498f89b-513d-4b4a-9e7c-529280342fc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         0\n",
              "1         0\n",
              "2         0\n",
              "3         0\n",
              "4         0\n",
              "         ..\n",
              "284802    0\n",
              "284803    0\n",
              "284804    0\n",
              "284805    0\n",
              "284806    0\n",
              "Name: Class, Length: 284807, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHH5cD7xDn76",
        "outputId": "b787eb03-2ea6-4fa5-c781-656a97ca55d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.69424232, -0.04407492,  1.6727735 , ...,  0.33089162,\n",
              "        -0.06378115,  0.24496426],\n",
              "       [ 0.60849633,  0.16117592,  0.1097971 , ..., -0.02225568,\n",
              "         0.04460752, -0.34247454],\n",
              "       [-0.69350046, -0.81157783,  1.16946849, ..., -0.13713686,\n",
              "        -0.18102083,  1.16068593],\n",
              "       ...,\n",
              "       [ 0.98002374, -0.18243372, -2.14320514, ...,  0.01103672,\n",
              "        -0.0804672 , -0.0818393 ],\n",
              "       [-0.12275539,  0.32125034,  0.46332013, ...,  0.26960398,\n",
              "         0.31668678, -0.31324853],\n",
              "       [-0.27233093, -0.11489898,  0.46386564, ..., -0.00598394,\n",
              "         0.04134998,  0.51435531]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting datast into training and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "p9EXpLiyG8-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#standard noramlizing the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X)\n",
        "X_test = scaler.transform(X)"
      ],
      "metadata": {
        "id": "zxCqAZUiBamL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#inporting the required libraries\n",
        "import keras\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LeakyReLU,PReLU,ELU\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout\n"
      ],
      "metadata": {
        "id": "PV9Dy1mbDrA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initializing ANN\n",
        "classifier = Sequential()\n"
      ],
      "metadata": {
        "id": "qWGwC1-pEHIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adding imput layer and first hidden layer\n",
        "classifier.add(Dense(units=10,kernel_initializer=\"he_normal\",activation=\"relu\",input_dim=X.shape[1]))\n",
        "classifier.add(Dropout(0.3))\n",
        "#units=output_dim: no of neurons in layer\n",
        "#kernel_initializer = init : weight initializer\n",
        "#activation: specify activation function\n",
        "#input_dim: no of features/columns in training dataset (only used in forst dense addition)\n",
        "\n",
        "#this creats neural network with 11 input nodes/nuerons and 6 1st hidden layer neurons\n",
        "\n",
        "#now trying to increase neurons/units and using he_normal weight initalizer\n",
        "\n",
        "#now adding dropout\n",
        "#adding second hidden layer\n",
        "classifier.add(Dense(units=20,kernel_initializer = \"he_normal\",activation=\"relu\"))\n",
        "classifier.add(Dropout(0.4))\n",
        "#adds six nodes/nuerons in second hidden layer\n",
        "\n",
        "#now trying to increase neurons/units and using he_normal weight initalizer\n",
        "\n",
        "#now adding dropout\n",
        "#adding third hidden layer\n",
        "classifier.add(Dense(units=15,kernel_initializer = \"he_normal\",activation=\"relu\"))\n",
        "classifier.add(Dropout(0.2))\n",
        "\n",
        "#added another hidden layer\n",
        "#now trying to increase neurons/units and using he_normal weight initalizer\n",
        "\n",
        "#now adding dropout\n",
        "#adding output layer\n",
        "classifier.add(Dense(units=1,kernel_initializer = \"he_normal\",activation=\"sigmoid\"))\n",
        "#1 node/neuron created as output\n",
        "\n",
        "#no dropout here cuz output layer"
      ],
      "metadata": {
        "id": "ZpskXBsyEKqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQnJvQJBGnGp",
        "outputId": "4e2e2af3-6f25-434b-97bf-daa425eb51c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 10)                300       \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 20)                220       \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 20)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 15)                315       \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 15)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 16        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 851 (3.32 KB)\n",
            "Trainable params: 851 (3.32 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compiling ANN\n",
        "classifier.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "#use binary cross_entropy when output is 0 or 1\n",
        "#use categorical_crossentropy when more that 2 classes present as output\n"
      ],
      "metadata": {
        "id": "lc3XskWbGsC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fitting training set into ANN\n",
        "classifier.fit(X_train,Y_train,validation_split=0.3,batch_size=25,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYo9RiFOGx--",
        "outputId": "8235f1a1-8c02-417c-86b1-efff3e173096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "6380/6380 [==============================] - 22s 3ms/step - loss: 0.0647 - accuracy: 0.9952 - val_loss: 0.0134 - val_accuracy: 0.9982\n",
            "Epoch 2/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0151 - accuracy: 0.9983 - val_loss: 0.0096 - val_accuracy: 0.9982\n",
            "Epoch 3/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0101 - accuracy: 0.9983 - val_loss: 0.0081 - val_accuracy: 0.9982\n",
            "Epoch 4/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0095 - accuracy: 0.9983 - val_loss: 0.0092 - val_accuracy: 0.9982\n",
            "Epoch 5/100\n",
            "6380/6380 [==============================] - 21s 3ms/step - loss: 0.0089 - accuracy: 0.9983 - val_loss: 0.0071 - val_accuracy: 0.9982\n",
            "Epoch 6/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0091 - accuracy: 0.9983 - val_loss: 0.0073 - val_accuracy: 0.9982\n",
            "Epoch 7/100\n",
            "6380/6380 [==============================] - 19s 3ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.0071 - val_accuracy: 0.9982\n",
            "Epoch 8/100\n",
            "6380/6380 [==============================] - 18s 3ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.0122 - val_accuracy: 0.9982\n",
            "Epoch 9/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0082 - accuracy: 0.9983 - val_loss: 0.0108 - val_accuracy: 0.9982\n",
            "Epoch 10/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0095 - accuracy: 0.9983 - val_loss: 0.0051 - val_accuracy: 0.9982\n",
            "Epoch 11/100\n",
            "6380/6380 [==============================] - 18s 3ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.0122 - val_accuracy: 0.9982\n",
            "Epoch 12/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.0071 - val_accuracy: 0.9982\n",
            "Epoch 13/100\n",
            "6380/6380 [==============================] - 19s 3ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 0.0070 - val_accuracy: 0.9982\n",
            "Epoch 14/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0075 - val_accuracy: 0.9982\n",
            "Epoch 15/100\n",
            "6380/6380 [==============================] - 18s 3ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.0066 - val_accuracy: 0.9982\n",
            "Epoch 16/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.0079 - val_accuracy: 0.9982\n",
            "Epoch 17/100\n",
            "6380/6380 [==============================] - 21s 3ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.0070 - val_accuracy: 0.9982\n",
            "Epoch 18/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0082 - accuracy: 0.9983 - val_loss: 0.0053 - val_accuracy: 0.9982\n",
            "Epoch 19/100\n",
            "6380/6380 [==============================] - 21s 3ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.0079 - val_accuracy: 0.9982\n",
            "Epoch 20/100\n",
            "6380/6380 [==============================] - 21s 3ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9982\n",
            "Epoch 21/100\n",
            "6380/6380 [==============================] - 19s 3ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0056 - val_accuracy: 0.9982\n",
            "Epoch 22/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0054 - val_accuracy: 0.9982\n",
            "Epoch 23/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.0108 - val_accuracy: 0.9982\n",
            "Epoch 24/100\n",
            "6380/6380 [==============================] - 18s 3ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0056 - val_accuracy: 0.9982\n",
            "Epoch 25/100\n",
            "6380/6380 [==============================] - 19s 3ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.0078 - val_accuracy: 0.9982\n",
            "Epoch 26/100\n",
            "6380/6380 [==============================] - 22s 3ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.0076 - val_accuracy: 0.9982\n",
            "Epoch 27/100\n",
            "6380/6380 [==============================] - 18s 3ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.0106 - val_accuracy: 0.9982\n",
            "Epoch 28/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0068 - val_accuracy: 0.9982\n",
            "Epoch 29/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.0074 - val_accuracy: 0.9982\n",
            "Epoch 30/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.0040 - val_accuracy: 0.9982\n",
            "Epoch 31/100\n",
            "6380/6380 [==============================] - 21s 3ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.0059 - val_accuracy: 0.9982\n",
            "Epoch 32/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.0053 - val_accuracy: 0.9982\n",
            "Epoch 33/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.0089 - val_accuracy: 0.9982\n",
            "Epoch 34/100\n",
            "6380/6380 [==============================] - 21s 3ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0042 - val_accuracy: 0.9982\n",
            "Epoch 35/100\n",
            "6380/6380 [==============================] - 21s 3ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0068 - val_accuracy: 0.9982\n",
            "Epoch 36/100\n",
            "6380/6380 [==============================] - 21s 3ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.0058 - val_accuracy: 0.9982\n",
            "Epoch 37/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0064 - val_accuracy: 0.9982\n",
            "Epoch 38/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.0100 - val_accuracy: 0.9982\n",
            "Epoch 39/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.0061 - val_accuracy: 0.9982\n",
            "Epoch 40/100\n",
            "6380/6380 [==============================] - 21s 3ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.0092 - val_accuracy: 0.9982\n",
            "Epoch 41/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0045 - val_accuracy: 0.9982\n",
            "Epoch 42/100\n",
            "6380/6380 [==============================] - 18s 3ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9982\n",
            "Epoch 43/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0056 - val_accuracy: 0.9982\n",
            "Epoch 44/100\n",
            "6380/6380 [==============================] - 21s 3ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.0075 - val_accuracy: 0.9982\n",
            "Epoch 45/100\n",
            "6380/6380 [==============================] - 18s 3ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0127 - val_accuracy: 0.9982\n",
            "Epoch 46/100\n",
            "6380/6380 [==============================] - 18s 3ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0042 - val_accuracy: 0.9982\n",
            "Epoch 47/100\n",
            "6380/6380 [==============================] - 21s 3ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.0057 - val_accuracy: 0.9982\n",
            "Epoch 48/100\n",
            "6380/6380 [==============================] - 18s 3ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0064 - val_accuracy: 0.9982\n",
            "Epoch 49/100\n",
            "6380/6380 [==============================] - 21s 3ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.0062 - val_accuracy: 0.9982\n",
            "Epoch 50/100\n",
            "6380/6380 [==============================] - 21s 3ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0061 - val_accuracy: 0.9982\n",
            "Epoch 51/100\n",
            "6380/6380 [==============================] - 21s 3ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.0068 - val_accuracy: 0.9982\n",
            "Epoch 52/100\n",
            "6380/6380 [==============================] - 19s 3ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.0052 - val_accuracy: 0.9982\n",
            "Epoch 53/100\n",
            "6380/6380 [==============================] - 19s 3ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0062 - val_accuracy: 0.9982\n",
            "Epoch 54/100\n",
            "6380/6380 [==============================] - 21s 3ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.0053 - val_accuracy: 0.9982\n",
            "Epoch 55/100\n",
            "6380/6380 [==============================] - 19s 3ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.0070 - val_accuracy: 0.9982\n",
            "Epoch 56/100\n",
            "6380/6380 [==============================] - 21s 3ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.0044 - val_accuracy: 0.9982\n",
            "Epoch 57/100\n",
            "6380/6380 [==============================] - 21s 3ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0054 - val_accuracy: 0.9982\n",
            "Epoch 58/100\n",
            "6380/6380 [==============================] - 21s 3ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.0086 - val_accuracy: 0.9982\n",
            "Epoch 59/100\n",
            "6380/6380 [==============================] - 21s 3ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.0053 - val_accuracy: 0.9982\n",
            "Epoch 60/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.0063 - val_accuracy: 0.9982\n",
            "Epoch 61/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.0092 - val_accuracy: 0.9982\n",
            "Epoch 62/100\n",
            "6380/6380 [==============================] - 18s 3ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.0040 - val_accuracy: 0.9982\n",
            "Epoch 63/100\n",
            "6380/6380 [==============================] - 18s 3ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0050 - val_accuracy: 0.9982\n",
            "Epoch 64/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0060 - val_accuracy: 0.9982\n",
            "Epoch 65/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.0054 - val_accuracy: 0.9982\n",
            "Epoch 66/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.0047 - val_accuracy: 0.9982\n",
            "Epoch 67/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.0073 - val_accuracy: 0.9982\n",
            "Epoch 68/100\n",
            "6380/6380 [==============================] - 18s 3ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0071 - val_accuracy: 0.9982\n",
            "Epoch 69/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9982\n",
            "Epoch 70/100\n",
            "6380/6380 [==============================] - 18s 3ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.0064 - val_accuracy: 0.9982\n",
            "Epoch 71/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.0043 - val_accuracy: 0.9982\n",
            "Epoch 72/100\n",
            "6380/6380 [==============================] - 19s 3ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0051 - val_accuracy: 0.9982\n",
            "Epoch 73/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.0050 - val_accuracy: 0.9982\n",
            "Epoch 74/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.0049 - val_accuracy: 0.9982\n",
            "Epoch 75/100\n",
            "6380/6380 [==============================] - 18s 3ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.0045 - val_accuracy: 0.9982\n",
            "Epoch 76/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.0058 - val_accuracy: 0.9982\n",
            "Epoch 77/100\n",
            "6380/6380 [==============================] - 22s 3ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.0046 - val_accuracy: 0.9982\n",
            "Epoch 78/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.0050 - val_accuracy: 0.9982\n",
            "Epoch 79/100\n",
            "6380/6380 [==============================] - 19s 3ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0065 - val_accuracy: 0.9982\n",
            "Epoch 80/100\n",
            "6380/6380 [==============================] - 21s 3ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.0051 - val_accuracy: 0.9982\n",
            "Epoch 81/100\n",
            "6380/6380 [==============================] - 21s 3ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0040 - val_accuracy: 0.9982\n",
            "Epoch 82/100\n",
            "6380/6380 [==============================] - 22s 3ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0065 - val_accuracy: 0.9982\n",
            "Epoch 83/100\n",
            "6380/6380 [==============================] - 19s 3ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.0057 - val_accuracy: 0.9982\n",
            "Epoch 84/100\n",
            "6380/6380 [==============================] - 21s 3ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.0070 - val_accuracy: 0.9982\n",
            "Epoch 85/100\n",
            "6380/6380 [==============================] - 18s 3ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.0050 - val_accuracy: 0.9982\n",
            "Epoch 86/100\n",
            "6380/6380 [==============================] - 21s 3ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.0062 - val_accuracy: 0.9982\n",
            "Epoch 87/100\n",
            "6380/6380 [==============================] - 21s 3ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.0043 - val_accuracy: 0.9982\n",
            "Epoch 88/100\n",
            "6380/6380 [==============================] - 21s 3ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.0067 - val_accuracy: 0.9982\n",
            "Epoch 89/100\n",
            "6380/6380 [==============================] - 23s 4ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.0071 - val_accuracy: 0.9982\n",
            "Epoch 90/100\n",
            "6380/6380 [==============================] - 19s 3ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.0076 - val_accuracy: 0.9982\n",
            "Epoch 91/100\n",
            "6380/6380 [==============================] - 22s 3ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.0063 - val_accuracy: 0.9982\n",
            "Epoch 92/100\n",
            "6380/6380 [==============================] - 21s 3ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.0063 - val_accuracy: 0.9982\n",
            "Epoch 93/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.0108 - val_accuracy: 0.9982\n",
            "Epoch 94/100\n",
            "6380/6380 [==============================] - 23s 4ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.0043 - val_accuracy: 0.9982\n",
            "Epoch 95/100\n",
            "6380/6380 [==============================] - 21s 3ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.0080 - val_accuracy: 0.9982\n",
            "Epoch 96/100\n",
            "6380/6380 [==============================] - 21s 3ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.0066 - val_accuracy: 0.9982\n",
            "Epoch 97/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0050 - val_accuracy: 0.9982\n",
            "Epoch 98/100\n",
            "6380/6380 [==============================] - 20s 3ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0087 - val_accuracy: 0.9982\n",
            "Epoch 99/100\n",
            "6380/6380 [==============================] - 22s 3ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.0075 - val_accuracy: 0.9982\n",
            "Epoch 100/100\n",
            "6380/6380 [==============================] - 19s 3ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0051 - val_accuracy: 0.9982\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x798c4884aaa0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking accuracy on test data\n",
        "y_pred=classifier.predict(X_test)\n",
        "y_pred=(y_pred>0.5) #consider greater than 0.5 as true and rest as false"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWvqk6fWCGJn",
        "outputId": "1a9a974a-44e2-4698-9e12-1c12f4e47f18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1781/1781 [==============================] - 2s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFYTcS4Ed6nT",
        "outputId": "b97f459a-80ea-40ef-9064-1f85d8c45027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Class\n",
              "0    56861\n",
              "1      101\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy=accuracy_score(Y_test,y_pred)\n",
        "cm=confusion_matrix(Y_test,y_pred)\n",
        "print(accuracy)\n",
        "print(cm)\n",
        "#model accuracy is high, but it was unable to classify any of the spam emails.\n",
        "#all 101 spam emails were falsely classified as not spam"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mICdF5qcCTWE",
        "outputId": "fecd512d-086a-4d02-e6e3-97c464ff5d6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9982268881008391\n",
            "[[56861     0]\n",
            " [  101     0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lets try oversampling the data to see if we get better accuracy\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "os=SMOTETomek(sampling_strategy=0.75)\n",
        "X_train_os,Y_train_os=os.fit_resample(X_train,Y_train)\n",
        "print(Counter(Y_train))\n",
        "print(Counter(Y_train_os))"
      ],
      "metadata": {
        "id": "p-Bb6Q_OZd-l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3988eee1-e477-47eb-9e69-d37394185ad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({0: 227454, 1: 391})\n",
            "Counter({0: 227453, 1: 170589})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fitting oversampled training dataset into ANN model\n",
        "classifier.fit(X_train_os,Y_train_os,validation_split=0.3,batch_size=25,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvBQPlqRC4gK",
        "outputId": "d014aeaa-f24e-4785-b8fe-96428dcae71c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "11146/11146 [==============================] - 36s 3ms/step - loss: 0.1822 - accuracy: 0.9590 - val_loss: 0.2597 - val_accuracy: 0.8933\n",
            "Epoch 2/100\n",
            "11146/11146 [==============================] - 34s 3ms/step - loss: 0.0738 - accuracy: 0.9769 - val_loss: 0.2192 - val_accuracy: 0.9022\n",
            "Epoch 3/100\n",
            "11146/11146 [==============================] - 34s 3ms/step - loss: 0.0670 - accuracy: 0.9785 - val_loss: 0.1524 - val_accuracy: 0.9286\n",
            "Epoch 4/100\n",
            "11146/11146 [==============================] - 35s 3ms/step - loss: 0.0643 - accuracy: 0.9789 - val_loss: 0.1492 - val_accuracy: 0.9359\n",
            "Epoch 5/100\n",
            "11146/11146 [==============================] - 38s 3ms/step - loss: 0.0615 - accuracy: 0.9797 - val_loss: 0.1580 - val_accuracy: 0.9388\n",
            "Epoch 6/100\n",
            "11146/11146 [==============================] - 36s 3ms/step - loss: 0.0620 - accuracy: 0.9800 - val_loss: 0.1721 - val_accuracy: 0.9189\n",
            "Epoch 7/100\n",
            "11146/11146 [==============================] - 40s 4ms/step - loss: 0.0588 - accuracy: 0.9801 - val_loss: 0.1421 - val_accuracy: 0.9392\n",
            "Epoch 8/100\n",
            "11146/11146 [==============================] - 34s 3ms/step - loss: 0.0574 - accuracy: 0.9808 - val_loss: 0.1400 - val_accuracy: 0.9438\n",
            "Epoch 9/100\n",
            "11146/11146 [==============================] - 35s 3ms/step - loss: 0.0559 - accuracy: 0.9812 - val_loss: 0.1181 - val_accuracy: 0.9466\n",
            "Epoch 10/100\n",
            "11146/11146 [==============================] - 31s 3ms/step - loss: 0.0554 - accuracy: 0.9814 - val_loss: 0.1214 - val_accuracy: 0.9450\n",
            "Epoch 11/100\n",
            "11146/11146 [==============================] - 32s 3ms/step - loss: 0.0561 - accuracy: 0.9814 - val_loss: 0.1398 - val_accuracy: 0.9457\n",
            "Epoch 12/100\n",
            "11146/11146 [==============================] - 32s 3ms/step - loss: 0.0555 - accuracy: 0.9815 - val_loss: 0.1332 - val_accuracy: 0.9480\n",
            "Epoch 13/100\n",
            "11146/11146 [==============================] - 34s 3ms/step - loss: 0.0550 - accuracy: 0.9818 - val_loss: 0.1644 - val_accuracy: 0.9498\n",
            "Epoch 14/100\n",
            "11146/11146 [==============================] - 33s 3ms/step - loss: 0.0567 - accuracy: 0.9816 - val_loss: 0.0976 - val_accuracy: 0.9567\n",
            "Epoch 15/100\n",
            "11146/11146 [==============================] - 33s 3ms/step - loss: 0.0541 - accuracy: 0.9822 - val_loss: 0.1225 - val_accuracy: 0.9470\n",
            "Epoch 16/100\n",
            "11146/11146 [==============================] - 38s 3ms/step - loss: 0.0543 - accuracy: 0.9820 - val_loss: 0.1342 - val_accuracy: 0.9411\n",
            "Epoch 17/100\n",
            "11146/11146 [==============================] - 35s 3ms/step - loss: 0.0562 - accuracy: 0.9816 - val_loss: 0.1358 - val_accuracy: 0.9458\n",
            "Epoch 18/100\n",
            "11146/11146 [==============================] - 39s 3ms/step - loss: 0.0550 - accuracy: 0.9822 - val_loss: 0.1087 - val_accuracy: 0.9503\n",
            "Epoch 19/100\n",
            "11146/11146 [==============================] - 38s 3ms/step - loss: 0.0533 - accuracy: 0.9824 - val_loss: 0.1716 - val_accuracy: 0.9364\n",
            "Epoch 20/100\n",
            "11146/11146 [==============================] - 33s 3ms/step - loss: 0.0536 - accuracy: 0.9823 - val_loss: 0.1331 - val_accuracy: 0.9465\n",
            "Epoch 21/100\n",
            "11146/11146 [==============================] - 38s 3ms/step - loss: 0.0528 - accuracy: 0.9825 - val_loss: 0.1213 - val_accuracy: 0.9485\n",
            "Epoch 22/100\n",
            "11146/11146 [==============================] - 33s 3ms/step - loss: 0.0536 - accuracy: 0.9821 - val_loss: 0.1442 - val_accuracy: 0.9457\n",
            "Epoch 23/100\n",
            "11146/11146 [==============================] - 36s 3ms/step - loss: 0.0528 - accuracy: 0.9827 - val_loss: 0.1425 - val_accuracy: 0.9504\n",
            "Epoch 24/100\n",
            "11146/11146 [==============================] - 33s 3ms/step - loss: 0.0536 - accuracy: 0.9824 - val_loss: 0.1060 - val_accuracy: 0.9494\n",
            "Epoch 25/100\n",
            "11146/11146 [==============================] - 38s 3ms/step - loss: 0.0546 - accuracy: 0.9821 - val_loss: 0.1317 - val_accuracy: 0.9493\n",
            "Epoch 26/100\n",
            "11146/11146 [==============================] - 34s 3ms/step - loss: 0.0528 - accuracy: 0.9826 - val_loss: 0.1153 - val_accuracy: 0.9525\n",
            "Epoch 27/100\n",
            "11146/11146 [==============================] - 37s 3ms/step - loss: 0.0524 - accuracy: 0.9825 - val_loss: 0.1456 - val_accuracy: 0.9439\n",
            "Epoch 28/100\n",
            "11146/11146 [==============================] - 33s 3ms/step - loss: 0.0521 - accuracy: 0.9832 - val_loss: 0.1457 - val_accuracy: 0.9446\n",
            "Epoch 29/100\n",
            "11146/11146 [==============================] - 37s 3ms/step - loss: 0.0517 - accuracy: 0.9830 - val_loss: 0.1205 - val_accuracy: 0.9525\n",
            "Epoch 30/100\n",
            "11146/11146 [==============================] - 37s 3ms/step - loss: 0.0518 - accuracy: 0.9827 - val_loss: 0.1010 - val_accuracy: 0.9513\n",
            "Epoch 31/100\n",
            "11146/11146 [==============================] - 34s 3ms/step - loss: 0.0518 - accuracy: 0.9828 - val_loss: 0.1048 - val_accuracy: 0.9534\n",
            "Epoch 32/100\n",
            "11146/11146 [==============================] - 33s 3ms/step - loss: 0.0510 - accuracy: 0.9830 - val_loss: 0.1223 - val_accuracy: 0.9506\n",
            "Epoch 33/100\n",
            "11146/11146 [==============================] - 37s 3ms/step - loss: 0.0522 - accuracy: 0.9828 - val_loss: 0.1041 - val_accuracy: 0.9516\n",
            "Epoch 34/100\n",
            "11146/11146 [==============================] - 38s 3ms/step - loss: 0.0525 - accuracy: 0.9827 - val_loss: 0.1155 - val_accuracy: 0.9503\n",
            "Epoch 35/100\n",
            "11146/11146 [==============================] - 37s 3ms/step - loss: 0.0510 - accuracy: 0.9831 - val_loss: 0.1280 - val_accuracy: 0.9478\n",
            "Epoch 36/100\n",
            "11146/11146 [==============================] - 33s 3ms/step - loss: 0.0523 - accuracy: 0.9829 - val_loss: 0.1021 - val_accuracy: 0.9537\n",
            "Epoch 37/100\n",
            "11146/11146 [==============================] - 36s 3ms/step - loss: 0.0520 - accuracy: 0.9829 - val_loss: 0.1145 - val_accuracy: 0.9522\n",
            "Epoch 38/100\n",
            "11146/11146 [==============================] - 31s 3ms/step - loss: 0.0512 - accuracy: 0.9831 - val_loss: 0.1393 - val_accuracy: 0.9531\n",
            "Epoch 39/100\n",
            "11146/11146 [==============================] - 31s 3ms/step - loss: 0.0504 - accuracy: 0.9830 - val_loss: 0.1586 - val_accuracy: 0.9429\n",
            "Epoch 40/100\n",
            "11146/11146 [==============================] - 33s 3ms/step - loss: 0.0502 - accuracy: 0.9831 - val_loss: 0.0952 - val_accuracy: 0.9567\n",
            "Epoch 41/100\n",
            "11146/11146 [==============================] - 32s 3ms/step - loss: 0.0507 - accuracy: 0.9832 - val_loss: 0.1145 - val_accuracy: 0.9483\n",
            "Epoch 42/100\n",
            "11146/11146 [==============================] - 31s 3ms/step - loss: 0.0509 - accuracy: 0.9832 - val_loss: 0.1185 - val_accuracy: 0.9466\n",
            "Epoch 43/100\n",
            "11146/11146 [==============================] - 31s 3ms/step - loss: 0.0515 - accuracy: 0.9833 - val_loss: 0.1093 - val_accuracy: 0.9501\n",
            "Epoch 44/100\n",
            "11146/11146 [==============================] - 31s 3ms/step - loss: 0.0500 - accuracy: 0.9830 - val_loss: 0.1028 - val_accuracy: 0.9503\n",
            "Epoch 45/100\n",
            "11146/11146 [==============================] - 32s 3ms/step - loss: 0.0510 - accuracy: 0.9830 - val_loss: 0.0834 - val_accuracy: 0.9624\n",
            "Epoch 46/100\n",
            "11146/11146 [==============================] - 34s 3ms/step - loss: 0.0503 - accuracy: 0.9835 - val_loss: 0.1160 - val_accuracy: 0.9525\n",
            "Epoch 47/100\n",
            "11146/11146 [==============================] - 32s 3ms/step - loss: 0.0507 - accuracy: 0.9833 - val_loss: 0.1303 - val_accuracy: 0.9503\n",
            "Epoch 48/100\n",
            "11146/11146 [==============================] - 37s 3ms/step - loss: 0.0504 - accuracy: 0.9832 - val_loss: 0.1119 - val_accuracy: 0.9494\n",
            "Epoch 49/100\n",
            "11146/11146 [==============================] - 32s 3ms/step - loss: 0.0489 - accuracy: 0.9835 - val_loss: 0.1643 - val_accuracy: 0.9557\n",
            "Epoch 50/100\n",
            "11146/11146 [==============================] - 37s 3ms/step - loss: 0.0501 - accuracy: 0.9833 - val_loss: 0.1217 - val_accuracy: 0.9548\n",
            "Epoch 51/100\n",
            "11146/11146 [==============================] - 36s 3ms/step - loss: 0.0501 - accuracy: 0.9834 - val_loss: 0.1023 - val_accuracy: 0.9559\n",
            "Epoch 52/100\n",
            "11146/11146 [==============================] - 37s 3ms/step - loss: 0.0505 - accuracy: 0.9835 - val_loss: 0.1328 - val_accuracy: 0.9460\n",
            "Epoch 53/100\n",
            "11146/11146 [==============================] - 37s 3ms/step - loss: 0.0497 - accuracy: 0.9832 - val_loss: 0.1169 - val_accuracy: 0.9528\n",
            "Epoch 54/100\n",
            "11146/11146 [==============================] - 35s 3ms/step - loss: 0.0492 - accuracy: 0.9832 - val_loss: 0.1036 - val_accuracy: 0.9514\n",
            "Epoch 55/100\n",
            "11146/11146 [==============================] - 38s 3ms/step - loss: 0.0508 - accuracy: 0.9833 - val_loss: 0.1160 - val_accuracy: 0.9508\n",
            "Epoch 56/100\n",
            "11146/11146 [==============================] - 32s 3ms/step - loss: 0.0501 - accuracy: 0.9836 - val_loss: 0.1033 - val_accuracy: 0.9515\n",
            "Epoch 57/100\n",
            "11146/11146 [==============================] - 37s 3ms/step - loss: 0.0491 - accuracy: 0.9837 - val_loss: 0.0953 - val_accuracy: 0.9562\n",
            "Epoch 58/100\n",
            "11146/11146 [==============================] - 35s 3ms/step - loss: 0.0493 - accuracy: 0.9835 - val_loss: 0.1468 - val_accuracy: 0.9428\n",
            "Epoch 59/100\n",
            "11146/11146 [==============================] - 32s 3ms/step - loss: 0.0502 - accuracy: 0.9834 - val_loss: 0.1223 - val_accuracy: 0.9521\n",
            "Epoch 60/100\n",
            "11146/11146 [==============================] - 36s 3ms/step - loss: 0.0498 - accuracy: 0.9834 - val_loss: 0.1244 - val_accuracy: 0.9470\n",
            "Epoch 61/100\n",
            "11146/11146 [==============================] - 31s 3ms/step - loss: 0.0495 - accuracy: 0.9835 - val_loss: 0.1536 - val_accuracy: 0.9423\n",
            "Epoch 62/100\n",
            "11146/11146 [==============================] - 31s 3ms/step - loss: 0.0495 - accuracy: 0.9836 - val_loss: 0.0863 - val_accuracy: 0.9584\n",
            "Epoch 63/100\n",
            "11146/11146 [==============================] - 31s 3ms/step - loss: 0.0494 - accuracy: 0.9834 - val_loss: 0.0930 - val_accuracy: 0.9542\n",
            "Epoch 64/100\n",
            "11146/11146 [==============================] - 32s 3ms/step - loss: 0.0491 - accuracy: 0.9834 - val_loss: 0.1059 - val_accuracy: 0.9540\n",
            "Epoch 65/100\n",
            "11146/11146 [==============================] - 31s 3ms/step - loss: 0.0503 - accuracy: 0.9833 - val_loss: 0.0890 - val_accuracy: 0.9594\n",
            "Epoch 66/100\n",
            "11146/11146 [==============================] - 30s 3ms/step - loss: 0.0490 - accuracy: 0.9837 - val_loss: 0.0909 - val_accuracy: 0.9592\n",
            "Epoch 67/100\n",
            "11146/11146 [==============================] - 31s 3ms/step - loss: 0.0491 - accuracy: 0.9837 - val_loss: 0.0991 - val_accuracy: 0.9556\n",
            "Epoch 68/100\n",
            "11146/11146 [==============================] - 32s 3ms/step - loss: 0.0488 - accuracy: 0.9835 - val_loss: 0.1841 - val_accuracy: 0.9578\n",
            "Epoch 69/100\n",
            "11146/11146 [==============================] - 33s 3ms/step - loss: 0.0496 - accuracy: 0.9835 - val_loss: 0.1169 - val_accuracy: 0.9497\n",
            "Epoch 70/100\n",
            "11146/11146 [==============================] - 36s 3ms/step - loss: 0.0488 - accuracy: 0.9838 - val_loss: 0.1185 - val_accuracy: 0.9560\n",
            "Epoch 71/100\n",
            "11146/11146 [==============================] - 35s 3ms/step - loss: 0.0496 - accuracy: 0.9837 - val_loss: 0.1207 - val_accuracy: 0.9521\n",
            "Epoch 72/100\n",
            "11146/11146 [==============================] - 37s 3ms/step - loss: 0.0511 - accuracy: 0.9834 - val_loss: 0.0932 - val_accuracy: 0.9555\n",
            "Epoch 73/100\n",
            "11146/11146 [==============================] - 38s 3ms/step - loss: 0.0491 - accuracy: 0.9838 - val_loss: 0.1180 - val_accuracy: 0.9516\n",
            "Epoch 74/100\n",
            "11146/11146 [==============================] - 33s 3ms/step - loss: 0.0490 - accuracy: 0.9837 - val_loss: 0.1403 - val_accuracy: 0.9436\n",
            "Epoch 75/100\n",
            "11146/11146 [==============================] - 38s 3ms/step - loss: 0.0494 - accuracy: 0.9838 - val_loss: 0.1033 - val_accuracy: 0.9547\n",
            "Epoch 76/100\n",
            "11146/11146 [==============================] - 37s 3ms/step - loss: 0.0486 - accuracy: 0.9837 - val_loss: 0.0966 - val_accuracy: 0.9576\n",
            "Epoch 77/100\n",
            "11146/11146 [==============================] - 34s 3ms/step - loss: 0.0495 - accuracy: 0.9835 - val_loss: 0.1096 - val_accuracy: 0.9537\n",
            "Epoch 78/100\n",
            "11146/11146 [==============================] - 36s 3ms/step - loss: 0.0492 - accuracy: 0.9838 - val_loss: 0.1046 - val_accuracy: 0.9551\n",
            "Epoch 79/100\n",
            "11146/11146 [==============================] - 37s 3ms/step - loss: 0.0480 - accuracy: 0.9838 - val_loss: 0.1048 - val_accuracy: 0.9552\n",
            "Epoch 80/100\n",
            "11146/11146 [==============================] - 36s 3ms/step - loss: 0.0487 - accuracy: 0.9834 - val_loss: 0.1429 - val_accuracy: 0.9526\n",
            "Epoch 81/100\n",
            "11146/11146 [==============================] - 34s 3ms/step - loss: 0.0511 - accuracy: 0.9836 - val_loss: 0.1023 - val_accuracy: 0.9555\n",
            "Epoch 82/100\n",
            "11146/11146 [==============================] - 34s 3ms/step - loss: 0.0486 - accuracy: 0.9837 - val_loss: 0.1079 - val_accuracy: 0.9539\n",
            "Epoch 83/100\n",
            "11146/11146 [==============================] - 35s 3ms/step - loss: 0.0483 - accuracy: 0.9838 - val_loss: 0.0934 - val_accuracy: 0.9546\n",
            "Epoch 84/100\n",
            "11146/11146 [==============================] - 37s 3ms/step - loss: 0.0493 - accuracy: 0.9837 - val_loss: 0.1290 - val_accuracy: 0.9473\n",
            "Epoch 85/100\n",
            "11146/11146 [==============================] - 38s 3ms/step - loss: 0.0499 - accuracy: 0.9835 - val_loss: 0.1157 - val_accuracy: 0.9531\n",
            "Epoch 86/100\n",
            "11146/11146 [==============================] - 38s 3ms/step - loss: 0.0504 - accuracy: 0.9835 - val_loss: 0.1791 - val_accuracy: 0.9528\n",
            "Epoch 87/100\n",
            "11146/11146 [==============================] - 33s 3ms/step - loss: 0.0486 - accuracy: 0.9836 - val_loss: 0.1173 - val_accuracy: 0.9487\n",
            "Epoch 88/100\n",
            "11146/11146 [==============================] - 34s 3ms/step - loss: 0.0489 - accuracy: 0.9834 - val_loss: 0.1072 - val_accuracy: 0.9497\n",
            "Epoch 89/100\n",
            "11146/11146 [==============================] - 34s 3ms/step - loss: 0.0481 - accuracy: 0.9837 - val_loss: 0.1190 - val_accuracy: 0.9498\n",
            "Epoch 90/100\n",
            "11146/11146 [==============================] - 33s 3ms/step - loss: 0.0502 - accuracy: 0.9834 - val_loss: 0.1321 - val_accuracy: 0.9476\n",
            "Epoch 91/100\n",
            "11146/11146 [==============================] - 34s 3ms/step - loss: 0.0475 - accuracy: 0.9842 - val_loss: 0.1089 - val_accuracy: 0.9543\n",
            "Epoch 92/100\n",
            "11146/11146 [==============================] - 33s 3ms/step - loss: 0.0493 - accuracy: 0.9836 - val_loss: 0.1357 - val_accuracy: 0.9526\n",
            "Epoch 93/100\n",
            "11146/11146 [==============================] - 37s 3ms/step - loss: 0.0495 - accuracy: 0.9836 - val_loss: 0.0934 - val_accuracy: 0.9588\n",
            "Epoch 94/100\n",
            "11146/11146 [==============================] - 38s 3ms/step - loss: 0.0491 - accuracy: 0.9833 - val_loss: 0.1018 - val_accuracy: 0.9544\n",
            "Epoch 95/100\n",
            "11146/11146 [==============================] - 33s 3ms/step - loss: 0.0503 - accuracy: 0.9836 - val_loss: 0.1400 - val_accuracy: 0.9500\n",
            "Epoch 96/100\n",
            "11146/11146 [==============================] - 33s 3ms/step - loss: 0.0493 - accuracy: 0.9836 - val_loss: 0.1097 - val_accuracy: 0.9578\n",
            "Epoch 97/100\n",
            "11146/11146 [==============================] - 37s 3ms/step - loss: 0.0485 - accuracy: 0.9838 - val_loss: 0.3804 - val_accuracy: 0.9448\n",
            "Epoch 98/100\n",
            "11146/11146 [==============================] - 31s 3ms/step - loss: 0.0493 - accuracy: 0.9835 - val_loss: 0.0925 - val_accuracy: 0.9599\n",
            "Epoch 99/100\n",
            "11146/11146 [==============================] - 32s 3ms/step - loss: 0.0481 - accuracy: 0.9836 - val_loss: 0.1121 - val_accuracy: 0.9530\n",
            "Epoch 100/100\n",
            "11146/11146 [==============================] - 34s 3ms/step - loss: 0.0478 - accuracy: 0.9838 - val_loss: 0.0956 - val_accuracy: 0.9594\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x798c49c3bbb0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking accuracy on test data\n",
        "y_pred_os=classifier.predict(X_test)\n",
        "y_pred_os=(y_pred_os>0.5) #consider greater than 0.5 as true and rest as false"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRJUn5VBByKr",
        "outputId": "81730f1f-e559-4516-c47d-8f6da7d1d103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1781/1781 [==============================] - 3s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking accuracy\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_os=accuracy_score(Y_test,y_pred_os)\n",
        "cm_os=confusion_matrix(Y_test,y_pred_os)\n",
        "print(accuracy_os)\n",
        "print(cm_os)\n",
        "#accuracy is less, but after oversampling, model was able to classify 88 out of 101 spam emails correctly.\n",
        "#hence this model is better"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ih-MRD5iCxMr",
        "outputId": "7f02790a-53c1-4341-9ca6-4a8184d724ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9970506653558513\n",
            "[[56706   155]\n",
            " [   13    88]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now let us create an ANN but with hyperparameter tuning using kerasTuner\n",
        "!pip install keras-tuner\n",
        "from tensorflow import keras\n",
        "from kerastuner import RandomSearch\n",
        "from keras import optimizers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_ThsfM2DPZk",
        "outputId": "587b177d-471b-428b-ad4c-ec9807bccb25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.10/dist-packages (1.4.7)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a function to create the general model with variable hyperparameters\n",
        "def build_model(hp):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(units=hp.Int('input_units',min_value=32,max_value=512,step=32),activation='relu',input_dim=X.shape[1]))\n",
        "  for i in range(hp.Int('num_layers',2,20)):\n",
        "    model.add(Dense(units=hp.Int('units_'+str(i),min_value=32,max_value=512,step=32),activation='relu'))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  model.compile(optimizer=optimizers.Adam(hp.Choice('learning_rate',[1e-2,1e-3,1e-4])),loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "DpKoT9X-DYET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initializing Random Search\n",
        "tuner=RandomSearch(build_model,objective='val_accuracy',max_trials=5,executions_per_trial=3,directory='Projects',project_name='CreditFraud')"
      ],
      "metadata": {
        "id": "AI-QkEvwDdXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#running random search on our inbalanced training data\n",
        "tuner.search(X_train,Y_train,epochs=5,batch_size=25,validation_split=0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ox_ox-8-jqah",
        "outputId": "77424d18-7b08-4b2f-9adf-347766519e01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 21m 39s]\n",
            "val_accuracy: 0.9991466005643209\n",
            "\n",
            "Best val_accuracy So Far: 0.9992343783378601\n",
            "Total elapsed time: 02h 10m 39s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.results_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2V0F6VjfD6SW",
        "outputId": "1ceb80cf-dae1-4413-e8bc-14655768bedc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in Projects/CreditFraud\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_accuracy\", direction=\"max\")\n",
            "\n",
            "Trial 3 summary\n",
            "Hyperparameters:\n",
            "input_units: 448\n",
            "num_layers: 10\n",
            "units_0: 512\n",
            "units_1: 320\n",
            "learning_rate: 0.0001\n",
            "units_2: 32\n",
            "units_3: 320\n",
            "units_4: 320\n",
            "units_5: 384\n",
            "units_6: 288\n",
            "units_7: 64\n",
            "units_8: 288\n",
            "units_9: 384\n",
            "units_10: 128\n",
            "units_11: 352\n",
            "Score: 0.9992343783378601\n",
            "\n",
            "Trial 1 summary\n",
            "Hyperparameters:\n",
            "input_units: 352\n",
            "num_layers: 9\n",
            "units_0: 320\n",
            "units_1: 160\n",
            "learning_rate: 0.0001\n",
            "units_2: 128\n",
            "units_3: 64\n",
            "units_4: 288\n",
            "units_5: 448\n",
            "units_6: 64\n",
            "units_7: 224\n",
            "units_8: 416\n",
            "Score: 0.9992246230443319\n",
            "\n",
            "Trial 2 summary\n",
            "Hyperparameters:\n",
            "input_units: 256\n",
            "num_layers: 12\n",
            "units_0: 288\n",
            "units_1: 320\n",
            "learning_rate: 0.0001\n",
            "units_2: 192\n",
            "units_3: 352\n",
            "units_4: 512\n",
            "units_5: 416\n",
            "units_6: 448\n",
            "units_7: 128\n",
            "units_8: 416\n",
            "units_9: 32\n",
            "units_10: 32\n",
            "units_11: 32\n",
            "Score: 0.9991660912831625\n",
            "\n",
            "Trial 0 summary\n",
            "Hyperparameters:\n",
            "input_units: 96\n",
            "num_layers: 9\n",
            "units_0: 320\n",
            "units_1: 192\n",
            "learning_rate: 0.001\n",
            "units_2: 32\n",
            "units_3: 32\n",
            "units_4: 32\n",
            "units_5: 32\n",
            "units_6: 32\n",
            "units_7: 32\n",
            "units_8: 32\n",
            "Score: 0.9991514682769775\n",
            "\n",
            "Trial 4 summary\n",
            "Hyperparameters:\n",
            "input_units: 448\n",
            "num_layers: 7\n",
            "units_0: 416\n",
            "units_1: 96\n",
            "learning_rate: 0.0001\n",
            "units_2: 320\n",
            "units_3: 256\n",
            "units_4: 192\n",
            "units_5: 352\n",
            "units_6: 480\n",
            "units_7: 224\n",
            "units_8: 320\n",
            "units_9: 352\n",
            "units_10: 128\n",
            "units_11: 128\n",
            "Score: 0.9991466005643209\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a model with the best parameters calculated using kerastuner\n",
        "model=tuner.get_best_models(num_models=1)[0]"
      ],
      "metadata": {
        "id": "_2irKFnvD8qP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgaV0MIFEBgb",
        "outputId": "4717896e-8886-455a-8849-f9cad2352571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 448)               13440     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               229888    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 320)               164160    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 32)                10272     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 320)               10560     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 320)               102720    \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 384)               123264    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 288)               110880    \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 64)                18496     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 288)               18720     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 384)               110976    \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 385       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 913761 (3.49 MB)\n",
            "Trainable params: 913761 (3.49 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking accuracy on test data\n",
        "y_pred_kt=model.predict(X_test)\n",
        "y_pred_kt=(y_pred_kt>0.5) #consider greater than 0.5 as true and rest as false"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YV4KXvWjERjC",
        "outputId": "aeb9a80c-de89-4149-b429-b92ed6e45b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1781/1781 [==============================] - 14s 8ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_kt=accuracy_score(Y_test,y_pred_kt)\n",
        "cm_kt=confusion_matrix(Y_test,y_pred_kt)\n",
        "print(accuracy_kt)\n",
        "print(cm_kt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_u9wb1dEYGM",
        "outputId": "be2cc840-245c-47fb-9980-95e4c32358f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.999385555282469\n",
            "[[56841    20]\n",
            " [   15    86]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Great\n",
        "#the ANN model created using keras tuner has the highest accuracy and the least number of combined false positives and false negatives\n",
        "#and this was only with training the model with the inbalanced dataset. imagine the accuracy if we were to train it with the balanced dataset"
      ],
      "metadata": {
        "id": "4_jWKeGJdT34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T-5jY8XddWs5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}